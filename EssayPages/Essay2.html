<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta author="Gabriella Hon">
    <meta name="description" content="This essay will explore the AI Action Summit 2025 and analyses the geopolotics and digital coloniality that is still prevalent.">
    <meta name="keywords"
        content="Essay 2, The internet, Geopolotics, Digital Coloniality, Artifical Intelligence, AI Governance, Algorithmic colonisation, DIGA3008, Interactive Media, HTML, CSS, JS">
    <title>Essay 2: The Internet, Geopolotics, and Digital Coloniality</title>
    <link rel="GoogleFont icon" type="image/png" href="../Images/BluePlanetIcon.png" />
    <link rel="stylesheet" href="../Styling/SubPage.css">
    <link rel="stylesheet" href="../Styling/NavStyling.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Sour+Gummy:ital,wdth,wght@0,100..125,100..900;1,100..125,100..900&display=swap"
        rel="stylesheet">
    <link rel="stylesheet"
        href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200&icon_names=planet" />
    <script src="../JavaScript/Navigation.js" defer></script>
</head>

<body class="Writings">
    <h1 class="p-name">Essay 2: The Internet, Geopolotics, and Digital Coloniality</h1>
    <div class="Navigation">
        <div class="IndexPg" id="MenuBtn">
            <span class="material-symbols-outlined">
                planet
            </span>
        </div>
        <nav class="NavBar">
            <ul>
                <li><a href="../index.html">Home</a></li>
                <li><a href="../PageIndex/Portfolio.html">Portfolio</a></li>
                <li><a href="../PageIndex/Blogs.html">Blogs</a></li>
                <li><a href="../PageIndex/Design.html">Design</a></li>
                <li><a href="../PageIndex/Essay.html">Essays</a>
                    <ul class="SubPages">
                        <li><a href="../EssayPages/Essay1.html">(1)</a></li>
                        <li class="ActivePage">(2)</li>
                        <li><a href="../EssayPages/FinalReflectin.html">(3)</a></li>
                    </ul>
                </li>
            </ul>
        </nav>
    </div>

    <article class="h-entry">
        <p>
            <a class="p-author h-card">Gabriella</a>
            <time class="dt-published" datetime="2025-05-13 18:22"> 13 June 2025</time>
        </p>
        <section class="e-content">
            <h2>Introduction</h2>
            <p>
                The Artificial Intelligence (AI) Action Summit, held in Paris, France in February 2025, brought together
                global leaders, policymakers, and technology experts to address the growing challenges of AI governance
                and digital sovereignty. Topics of geopolitical competition were seen during discussions however, the
                summit became a focal point for discussions on AI&apos;s role as a strategic asset, shaping
                international
                power dynamics and reinforcing existing digital inequalities. Key debates revolved around the ethical
                regulation of AI, data governance policies, and the disproportionate influence of technologically
                dominant nations over global AI infrastructure. The summit highlighted concerns over digital coloniality
                where there would be emerging technologies which deepen dependencies on Western-developed software,
                cloud services, and regulatory frameworks. Many nations wanted to position themselves to a point where
                there would be control over AI innovation. The summit underlined the increasing division of the digital
                landscape, reflecting broader tensions between open collaboration and protectionist approaches to
                technological development.
            </p>

            <h2>Geopolitical Conflicts in AI Governance</h2>
            <p>
                The Élysée AI Action Summit report [1] highlights the mirrored geopolitical conflicts shown during AI
                governance debates. The report shows that some nations advocated for open AI ecosystems and other
                nations prioritising technological nationalism. The U.S. and European nations advocated for AI
                regulation to focus on security while nations such as China spoke about AI as a tool for economic
                independence. This shows the digital hegemonies where the space of AI becomes the topic of debate for
                the influences over global digital infrastructure.
            </p>

            <h2>Algorithmic Colonisation and Western Dominance</h2>
            <p>
                Birhane [2] argues that AI development is often dictated by Western economic interests which then
                marginalises expressions and voices from the Global South. This then brings about algorithmic
                colonisation where there is a drive for maximum profit, control and influence of Western software and
                infrastructure needed for African problems. There are often biased results which stem from Western
                models and then a failure to address local needs and challenges. Corporate profit is often prioritised
                over social implications when AI solutions are introduced which again disregards local challenges by
                depending on Western solutions.
            </p>

            <h2>Digital Inequalities and AI Accessibility</h2>
            <p>
                Lutz [3] examines digital inequalities in the context of AI and big data. There are highlighted
                disparities shown in access, skills, and outcomes which in turn shape technological adoption. The
                framework of first-, second-, and third-level digital divides is particularly relevant and seen in the
                AI accessibility debates at the Élysée AI Action Summit [1]. The first-level digital divides show
                disparities in internet connectivity, infrastructure, and the availability of hardware which show the
                effect on marginalised communities that may not have the same or similar means as communities that are
                more dominant. On the second level of digital divides there are differences shown in digital skills and
                the use of technology. In some cases, there is access to the relevant digital platforms or hardware
                however there is a lack of skills needed to meaningfully engage with AI-driven platforms which then
                reinforces the existing socio-economic inequalities. Finally, the third-level digital divides show
                unequal outcomes of digital technology use. There can be amplified biases in AI-driven decision-making
                which lead to discriminatory hiring practices, financial exclusion, and algorithmic surveillance that
                disproportionately impacts vulnerable populations.
            </p>
            <p>
                During the summit, discussions centred on how AI governance disproportionately benefits technologically
                dominant nations and reinforces existing inequalities in nations that are not as technologically
                advanced or are dependent on the technologically dominant nations. This aligns with Lutz&apos;s argument
                that
                AI-driven decision-making often excludes marginalised communities. There are often instances where
                excitement is built around decisions for AI that do not include the marginalised communities since the
                focus is the technologically dominant nations. This is either through biased algorithms or restricted
                access to AI infrastructure which Birhane also examines. Although the summit had an emphasis on
                inclusive AI policies to try and bridge the gap between the biased algorithms or restricted access to AI
                infrastructure and the local challenges. Lutz advises that such efforts such as these must go beyond
                surface-level accessibility and address deeper systemic inequalities.
            </p>

            <h2>Sociotechnical Foresight and AI Regulation</h2>
            <p>
                Shakir et al. [4] introduce sociotechnical foresight as a framework for understanding how AI governance
                is shaped by historical patterns of power and control. They argue that AI regulation is not merely a
                technical necessity, but a strategic tool used by dominant nations to reinforce their influence over
                global digital infrastructure. Having a larger influence over the global digital infrastructure means
                that the decisions surrounding the regulations would primarily benefit the nation with the larger
                influence. This aligns with discussions at the Élysée AI Action Summit, where Western nations framed AI
                governance as a security imperative, advocating for stricter regulations that favour established tech
                powers. The third-level digital divide can be seen in the €109 billion investment that France is
                undertaking into AI infrastructure [5] which reinforces how dominant nations want to have a larger
                influence over global digital infrastructure.

            </p>

            <h2>Rethinking AI Governance for Global Inclusion</h2>
            <p>
                The summit&apos;s emphasis on AI accessibility, ethical deployment, and regulatory oversight reflects
                Shakir
                et al.&apos;s argument that AI governance is deeply intertwined with geopolitical interests. By
                controlling
                AI standards, dominant nations dictate the terms of technological development, reinforcing digital
                coloniality - a system where emerging economies remain dependent on Western software and AI frameworks.
                With the dependence on Western software and frameworks, emerging economies and marginalised nations fall
                behind and heavily depend on dominant nations.
            </p>

            <h2>Conclusion</h2>
            <p>
                The AI Action Summit 2025 served as an important reflection of the ongoing tensions of dominant nations
                in AI governance. The summit illustrated how geopolitical interests shape digital sovereignty,
                infrastructure control, and technological accessibility. While there were discussions at the summit
                which emphasized ethical AI deployment and global cooperation, the realities of digital coloniality, as
                highlighted by Birhane [2], Lutz [3], and Shakir et al. [4], suggest that AI development remains deeply
                entwined with Western economic priorities. Direct effort to work alongside the Global South to ensure
                that there is no reinforcement of economic dependencies and mirroring of digital hegemony is needed.
            </p>
            <p>
                The main discussions of the summit highlighted the need for rethinking AI governance and showing that AI
                governance should go beyond corporate interests and national security. Dominant nations should advocate
                for equitable, open-source and adaptive AI solutions that are inclusive to all communities to establish
                diversities in AI governance rather than reinforce apparent technological hierarchies.
            </p>
        </section>

        <section class="e-content">
            <h2>References:</h2>
            <p>
                [1] Élysée, “AI Action Summit,” Feb. 2025. Accessed: 13 Jun. 2025. [Online]. Available: <a
                    class="Reference"
                    href="https://www.elysee.fr/admin/upload/default/0001/17/786758b38da7b4c16f26dc56e51884b3346684aa.pdf"
                    target="_blank">AI Action Summit</a>
            </p>
            <p>
                [2] A. Birhane, “Algorithmic colonization of Africa,” SCRIPTed, vol. 17, no. 2, pp. 389&ndash;409, 2020,
                doi: 10.2966/scrip.170220.389</a>
            </p>
            <p>
                [3] C. Lutz, “Digital inequalities in the age of artificial intelligence and big data,” Hum. Behav.
                Emerg. Technol., vol. 1, no. 2, pp. 141&ndash;148, 2019, doi: 10.1002/hbe2.140.
            </p>
            <p>
                [4] S. Mohamed, M.-T. Png, and W. Isaac, “Decolonial AI: Decolonial theory as sociotechnical foresight
                in artificial intelligence,” Philos. Technol., vol. 33, no. 4, pp. 659&ndash;684, 2020, doi:
                10.1007/s13347-020-00405-8.
            </p>
            <p>
                [5] “Paris AI Action Summit 2025 and global AI initiatives: A unified call for ethical AI innovation and
                global cooperation,” Data for Policy. Accessed: 13 Jun. 2025. [Online].
                Available: <a class="Reference"
                    href="https://dataforpolicy.org/paris-ai-action-summit-2025-and-global-ai-initiatives-a-unified-call-for-ethical-ai-innovation-and-global-cooperation/"
                    target="_blank"> Paris AI Action Summit 2025 and Global AI Intiatives</a>
            </p>
        </section>
    </article>
</body>

</html>